%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Configuration et préambule du document

\documentclass[a4paper, 12pt]{report} % Classe de document pour rapport

% ----------------------------------------------------------------------
% Importation des packages nécessaires

%\usepackage{xurl}      % Gestion des longues URLs

\usepackage{microtype} % Meilleure justification du texte

% Gestion des commentaires
\usepackage{todonotes}

% Gestion des sections et des titres
\usepackage{titlesec} 

% Police standard sous LaTeX (Latin Modern)
\usepackage{lmodern} 

% Bibliographie (si besoin, décommentez la ligne ci-dessous)
% \addbibresource{Mabiblio.bib} 

% Gestion des citations
\usepackage{cite} 

% Langue française et encodage
\usepackage[french]{babel}      % Pour les règles typographiques françaises
\usepackage[utf8]{inputenc}     % Pour l'encodage UTF-8
\usepackage[T1]{fontenc}        % Pour les caractères accentués
\usepackage{newtxtext} % Optionnel : charge une police alternative compatible

% Gestion des URL et césures correctes
\usepackage[hyphens]{url} 

% Mathématiques (symboles et formats avancés)
\usepackage{amsmath, amsfonts, amssymb}

% Mise en page et marges
\usepackage[a4paper, top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry} 

\setlength{\marginparwidth}{2.5cm}

% Gestion des graphiques, positionnement et ajustement
\usepackage{graphicx, float, adjustbox, caption}

% Pour des symboles mathématiques et physiques avancés
\usepackage{isomath} 

% Espacement entre les lignes
\usepackage{setspace}
\setstretch{1.2} % Espacement 1.2 pour un meilleur confort de lecture

% Couleurs avancées
\usepackage[dvipsnames]{xcolor}

% Listes personnalisées
\usepackage{enumitem, pifont}

% Boîtes colorées (par exemple pour mettre en valeur des parties du texte)
\usepackage{tcolorbox}

% Hyperliens et interaction dans le PDF
\usepackage[
    pdfauthor={{Groupe IOD}}, 
    pdftitle={{À LA RECHERCHE DU BONHEUR}}, 
    pdfstartview=Fit, 
    pdfpagelayout=SinglePage, 
    pdfnewwindow=true, 
    bookmarksnumbered=true, 
    breaklinks, 
    colorlinks, 
    linkcolor=blue, 
    urlcolor=black, 
    citecolor=cyan, 
    linktoc=all
]{hyperref} 

% ----------------------------------------------------------------------
% Personnalisation des listes
\usepackage{enumitem}

% Réglage global pour les listes
\setlist[itemize]{itemsep=0pt, topsep=0pt} % Réduit les espacements
\setlist[enumerate]{itemsep=0pt, topsep=0pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Définition des titres et commandes personnalisées

% ----------------------------------------------------------------------
% Définition des commandes personnalisées

% Texte en gras et italique
\newcommand{\grasital}[1]{\textbf{\textit{#1}}}

% Abréviation du "Service Après-Vente"
\newcommand{\SAV}{\textbf{Service Après-Vente}}

% Vecteur colonne 3x1
\newcommand{\vcol}[3]{\begin{pmatrix} #1 \\ #2 \\ #3 \end{pmatrix}}

% Ligne horizontale personnalisée (épaisseur ajustable)
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% ----------------------------------------------------------------------
% Gestion des espacements pour les titres (exemple commenté)

% Personnalisation de l'espacement des sections
% \titlespacing*{\section}{0pt}{-100pt}{1cm} 
% Explications :
% - Premier paramètre : indentation du titre (ici 0pt)
% - Deuxième paramètre : espacement avant le titre (ici -100pt)
% - Troisième paramètre : espacement après le titre (ici 1cm)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Personnalisation des titres avec titlesec

% Activer la numérotation des sous-sous-sections
\setcounter{secnumdepth}{3}

% ----------------------------------------------------------------------
% Personnalisation des chapitres
\titleformat{\chapter}[block] % Utilisation du style "block" pour alignement propre
{\normalfont\huge\bfseries} % Style : taille et gras
{Chapitre~\thechapter :} % Numérotation avec texte personnalisé
{0.5em} % Espacement entre numéro et titre
{} % Alignement à gauche pour le titre complet

% Personnalisation des sections
\titleformat{\section}[block]
{\normalfont\Large\bfseries} % Taille "Large", gras
{\thesection.} % Numérotation (exemple : 1.1)
{0.5em} % Espacement entre numéro et titre
{}

% Personnalisation des sous-sections
\titleformat{\subsection}[block]
{\normalfont\large\bfseries} % Taille "large", gras
{\thesubsection.} % Numérotation (exemple : 1.1.1)
{0.5em}
{}

% Personnalisation des sous-sous-sections
\titleformat{\subsubsection}[block]
{\normalfont\normalsize\bfseries}       % Formatage : taille "\normalsize" et texte en gras
{\thesubsubsection.}               % Affiche la numérotation (exemple : 1.1.1)
{0.5em}           % Espacement entre la numérotation et le titre
{}                                 % Pas de texte supplémentaire avant le titre


% Espacement pour les chapitres
\titlespacing*{\chapter}{0pt}{0pt}{20pt} % {indentation}{espace avant}{espace après}

% Espacement pour les sections
\titlespacing*{\section}{0pt}{15pt}{10pt} % {indentation}{espace avant}{espace après}

% Espacement pour les sous-sections
\titlespacing*{\subsection}{0pt}{10pt}{6pt}

% Espacement pour les sous-sous-sections
\titlespacing*{\subsubsection}{0pt}{8pt}{2pt}


% Espacement paragraphe
% Définition de commande pour l'espacement des paragraphes
\newcommand{\configEspacementParagraphe}[2]{
    \setlength{\parindent}{#1} % Indentation des paragraphes
    \setlength{\parskip}{#2}   % Espacement vertical entre les paragraphes
}

% Application de la configuration
\configEspacementParagraphe{20pt}{10pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Début du document

\begin{document} 

% Configuration mathématique pour afficher tous les mathématiques en mode "display"
\everymath{\displaystyle}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% La page de garde

\begin{titlepage}
\begin{center} % Centrer le contenu de la page

% ----------------------------------------------------------------------
% En-tête de l'université
\textsc{\huge Université de Bordeaux} \\[2cm]

% Intitulé du cursus (personnalisé si nécessaire)
% \textsc{\Large \textcolor{blue}{Que de l'amour}} \\[1.5cm] % Exemple en commentaire
\textsc{\large {Image, Optimisation et Sciences des Données}} \\[0.5cm] 

% ----------------------------------------------------------------------
% Titre du projet
\HRule \\[0.6cm]
{\Huge\bfseries\textcolor{Red}{- PROJET IOD -}} \\[0.25cm]
\HRule \\[1.5cm]

% ----------------------------------------------------------------------
% Liste des auteurs
\Large\textbf{Auteurs :} \\[0.5cm]
Farius \textsc{AINA} \\[0.5cm]
Mohamed El-Amine \textsc{BENHAMIDA} \\[0.5cm]
Radia \textsc{MADDI} \\[0.5cm]
Mamour \textsc{N'DIAYE} \\[2.5cm]

% ----------------------------------------------------------------------
% Encadrant
\Large\textbf{Encadrant :} \\[0.5cm]
Antoine \textsc{GUENNEC} \\[0.5cm]

\end{center}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table des matières

% Définition de la profondeur des sections affichées
% tocdepth = 3 : inclut les chapitres, sections, sous-sections, et sous-sous-sections
\setcounter{tocdepth}{1} 

% Génération automatique de la table des matières
\tableofcontents 

% Insérer une nouvelle page après la table des matières
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Objectifs }
L'objectif principal du présent projet est de développer une fonction de régularisation \( R(x) \) paramétrée par un réseau de neurones, en se basant sur les travaux de Goujon et al. Cette approche vise à exploiter les propriétés de convexité ou de faible convexité de la fonction de régularisation afin d'améliorer la résolution des problèmes inverses par rapport aux méthodes classiques.

Et plus spéficiquement il s'agira de :
\begin{itemize}
    \item [$\blacktriangleright$] Comprendre les principes des méthodes 'Plug-and-Play' appliquées à la résolution des problèmes inverses.
    \item [$\blacktriangleright$] Étudier le fonctionnement des fonctions de régularisation basées sur des réseaux de neurones.
    \item [$\blacktriangleright$] Implémenter le code source et comparer ces approches aux méthodes classiques sur différents problèmes inverses.
\end{itemize} 

\newpage


\chapter{Approches variationnelle et plug and play pour la résolution de problèmes inverses}


\section{Introduction aux  problèmes inverses en imagerie}
 
La résolution des problèmes inverses consiste à retrouver l'information originale d'un objet d'étude à partir d'observations dégradées. Grâce à sa flexibilité, cette approche permet de traiter des données variées (images 2D, 3D, hyperspectrales) en utilisant des techniques spécifiques, telles que la reconstruction d'image ou l'analyse spectrale.

La première étape pour résoudre un problème inverse consiste à établir le modèle direct, qui s'exprime sous la forme la plus simple :
\[
z = A \bar{u} + \epsilon \quad (1)
\]
où \( \bar{u} \) représente l'objet original (inconnu), généralement une image composée de \( N \) pixels. \( A \) désigne une transformation linéaire ou non linéaire, modélisant le dispositif d'acquisition. \( \epsilon \) correspond à une perturbation stochastique, autrement dit un bruit de mesure, supposé ici additif. Enfin, \( z \) représente les observations, typiquement une image composée de \( M \) pixels.


\subsection{Définition d'un problème inverse}

Le problème inverse consiste alors à estimer une image $\hat{u}$ proche de $\overline{u}$ à partir des informations contenues dans $z$, d'une connaissance complète ou partielle de $A$, des statistiques du bruit, et d'a priori sur la classe d'images à reconstruire. Cette unique équation décrit de nombreux problèmes inverses en traitements d'images, tels que le débruitage ($A$ est l'opérateur identité et $z$ est une version bruitée de l'image originale) ou la déconvolution ($A$ est un opérateur de convolution et $z$ une version floue et bruitée de l'image originale), couramment rencontrés en astronomie ou en microscopie. Elle décrit également de nombreux modèles d'acquisition utilisés en imagerie médicale, notamment en imagerie par résonance magnétique (IRM : échantillonnage dans le domaine de Fourier) ou en tomographie (transformée de Radon). L'intérêt des approches basées sur les problèmes inverses réside dans leur formulation générale, qui les rend applicables à de nombreuses modalités, et dans leur capacité à fournir des estimateurs $\hat{u}$ ayant d'excellentes propriétés.


\subsection{Exemples d'utilisation des problèmes inverses en traitement d'image et de signal.}

\subsubsection{Utilisation pour les caméras à un  pixel}

Une caméra à pixel unique est un dispositif qui capture des images en utilisant un seul capteur. Elle fonctionne en corrélant une image réelle avec des vecteurs aléatoires de Bernoulli et en mesurant ces corrélations sur un unique pixel. Cela permet de reconstruire l'image à partir d'un nombre limité de mesures.

Cette reconstruction constitue un problème inverse, car elle consiste à retrouver un signal complet (l'image) à partir de données incomplètes (les mesures). Un petit miroir, étant activé ou désactivé, contribue ou non à l'intensité lumineuse mesurée par le capteur. De cette manière, on réalise le produit scalaire \( \langle z, b \rangle \) de l'image \( z \) avec un vecteur \( b \) contenant des uns aux emplacements correspondant aux miroirs activés et des zéros ailleurs.

On peut également réaliser des produits scalaires avec des vecteurs \( a \) contenant uniquement \( +1 \) et \( -1 \) avec une probabilité égale, en définissant deux vecteurs auxiliaires \( b_1, b_2 \in \{0,1\}^N \) via :
\[
b_1^j = 
\begin{cases} 
1 & \text{si } a_j = 1, \\
0 & \text{si } a_j = -1 
\end{cases}, \quad
b_2^j = 
\begin{cases} 
1 & \text{si } a_j = -1, \\
0 & \text{si } a_j = 1 
\end{cases}
\]

de sorte que \( \langle z, a \rangle = \langle z, b_1 \rangle - \langle z, b_2 \rangle \). En choisissant des vecteurs \( a_1, \ldots, a_m \) indépendamment au hasard, avec des entrées prenant les valeurs \( \pm 1 \) avec une probabilité égale, les intensités mesurées \( y = \langle z, a \rangle \) correspondent à des produits scalaires avec des vecteurs de Bernoulli indépendants. Par conséquent, nous avons \( y = Az \), où \( A \in \mathbb{R}^{m \times N} \) est une matrice de Bernoulli (aléatoire). Cette opération est appliquée sur l'image \( z \).


En rappelant que \( z = Wx \) où \( x \in \mathbb{R}^N \) est un vecteur parcimonieux (un vecteur dont la plupart des éléments sont nuls ou proches de zéro)  et \( W \in \mathbb{R}^{N \times N} \) est une matrice unitaire représentant la transformation 
et en écrivant \( A' = AW \), on obtient le système :
\[
y = A'x,
\]
 Dans cette situation, les mesures sont prises séquentiellement. Comme ce processus peut être chronophage, il est souhaitable de n'utiliser qu'un nombre limité de mesures. Ainsi, nous arrivons au problème standard de compression de l'information. Ce dernier permet la reconstruction de \( x \) à partir de \( y \), et l'image est finalement déduite comme \( z = Wx \).


\begin{figure}[H] % 'h' pour positionner ici
    \centering
    \includegraphics[width=0.8\textwidth]{camera 1 pixel.png}
    \caption{Représentation schématique d'une caméra à pixel unique  \cite{foucart2013invitation}}
    \label{fig:1}
\end{figure}


\subsubsection{Utilisation en imagerie par résonance magnétique (IRM) }

L'imagerie par résonance magnétique (IRM) est une technologie médicale avancée qui utilise des champs magnétiques et des ondes radiofréquence pour visualiser les structures internes du corps. Les atomes d'hydrogène présents dans les tissus réagissent aux champs magnétiques en émettant des signaux, qui sont mesurés et traités pour reconstruire des images détaillées des tissus et organes.

Les problèmes inverses en IRM sont essentiels pour transformer ces signaux en images anatomiques significatives. La reconstruction d'images précises est complexe en raison de la nature indirecte et bruitée des données. Les techniques de résolution de problèmes inverses sont utilisées pour convertir les mesures brutes en images interprétables. Cela implique de traiter les données pour corriger les imperfections et réduire le bruit, puis d'appliquer des méthodes d'optimisation et de régularisation pour obtenir des images de haute qualité.

L'opérateur linéaire associé à l'IRM dans la résolution de problèmes inverses est souvent représenté par la matrice de Fourier. En termes mathématiques, l'IRM mesure les coefficients de Fourier de la magnétisation transverse du corps. Ces coefficients sont obtenus en appliquant une transformation de Fourier aux signaux mesurés par les capteurs.

En notation, si \( X(z) \) représente la magnétisation transverse à la position \( z \), les mesures \( y \) obtenues par l'IRM peuvent être exprimées comme :
\[
y = \mathcal{F}(X(z))
\]
où \( \mathcal{F} \) est l'opérateur de transformation de Fourier. La reconstruction de l'image du corps à partir des mesures \( y \) implique l'inversion de cette transformation, ce qui constitue le problème inverse en IRM.


\begin{figure}[H] % 'H' pour positionner ici
    \begin{center}
    \includegraphics[scale=0.5]{cerveau irm.png}
    \caption{Image capturée par l'IRM (Image disponible \href{https://www.lesnumeriques.com/sante-sport/des-images-inedites-du-cerveau-humain-ont-ete-capturees-par-le-plus-puissant-irm-au-monde-n220416.html}{\textcolor{green}{ici}})}
    \label{fig:2}
    \end{center}
\end{figure}


\section{Méthode variationnelle}
Les premiers travaux sur les problèmes inverses remontent à la définition du concept de problème bien posé, proposé par J. Hadamard en 1902 \cite{hadamard1902problemes}, basé sur trois critères fondamentaux : l’existence, l’unicité et la stabilité de la solution. Par nature, la majorité des problèmes inverses rencontrés en traitement du signal et des images (TSI) sont considérés comme mal posés. Lorsque \( A \) n’est pas inversible, de nombreuses recherches ont été initiées pour proposer des méthodes de résolution, notamment l’approche du maximum de vraisemblance introduite par R.A. Fisher en 1922. Cette méthode se ramène à la résolution des moindres carrés lorsque \( \epsilon \) est un bruit blanc gaussien, et à la pseudo-inverse de Moore-Penrose si \( A \) est en plus linéaire, selon l’expression :
\[
u \in \text{Argmin}_u \|Au - z\|_2^2 = (A^*A)^{-1}A^*z,
\]
où \( A^* \) désigne l’adjoint de \( A \).

Cependant, ces estimateurs sont souvent impraticables ou produisent des solutions irrégulières en raison de l’amplification du bruit de mesure, principalement causée par le mauvais conditionnement de \( A \). Pour pallier cette difficulté, des solutions visant à améliorer le conditionnement de \( A \), telles que la décomposition en valeurs singulières tronquées (SVD tronquée) \cite{hansen1998rank}, ont été proposées. Une autre approche consiste à régulariser la solution par des méthodes variationnelles pénalisées.

Depuis ces travaux fondateurs, les avancées majeures ont porté sur la résolution des problèmes inverses par la minimisation d’un critère variationnel de la forme suivante :
\[
\mathbf{u} \in \text{Argmin}_{\mathbf{u} \in \mathcal{C}} \left( \psi(A\mathbf{u}, \mathbf{z}) + \lambda \phi(\mathbf{u}) \right), \tag{2}
\]
où \( \mathcal{C} \subset \mathbb{R}^N \) représente l’ensemble des solutions admissibles, \( \psi \) est une mesure de "distance" entre les observations \( \mathbf{z} \) et leur modèle (représentation mathématique des données observées), \( \phi \) est un terme de pénalisation qui limite les solutions irrégulières, et \( \lambda > 0 \) est un paramètre de régularisation permettant de trouver un équilibre entre la fidélité aux données (\( \psi \)) et la régularisation (\( \phi \)).

Cette minimisation générique permet de traiter efficacement le mauvais conditionnement des matrices (opérateurs) lorsque \( \lambda > 0 \). Par ailleurs, les solutions irrégulières obtenues par maximum de vraisemblance peuvent être retrouvées en prenant \( \lambda = 0 \).

\subsection{Hyperparamètre et Dimensionalité}

\subsubsection{Hyperparamètre}
Une question sensible dans la résolution des problèmes inverses par approche variationnelle concerne le choix de l’hyperparamètre \( \lambda \). Les principales techniques proposées pour régler automatiquement ce paramètre sont la minimisation d’estimateurs de l’erreur quadratique moyenne 
(estimateur non-biaisé du risque de Stein : SURE)\cite{deledalle2014stein}, la validation croisée généralisée (GCV) \cite{golub1979generalized}, la courbe en L \cite{hansen1998rank}, ou les approches bayésiennes par marginalisation de la distribution a posteriori ou méthodes MCMC (ces dernières nécessitant de spécifier la densité de probabilité de \( \lambda \)).

\subsubsection{Dimensionalité}
La résolution de problèmes inverses en imagerie fait face à une augmentation constante du volume de données à traiter, mais bénéficie également de l’accroissement de la puissance de calcul des ordinateurs. Les développements méthodologiques et algorithmiques, combinés aux avancées en performances numériques, ont permis de passer de l’analyse d’images composées de \( N = 10^3 \) pixels dans les années 80 \cite{geman1984stochastic} à l’analyse d’images hyperspectrales de taille \( 10^7 \) \cite{guilloteau2020hyperspectral} quarante ans plus tard, et ce, pour un temps de calcul équivalent. Ces avancées ont également permis d’améliorer les performances de reconstruction grâce à l’utilisation de pénalisations \( \phi \) finement choisies.

\subsection{Pénalisation/Régularisation}
Une première catégorie de pénalisations concerne des fonctions différentiables et convexes, telles que la régularisation de Tikhonov \cite{tikhonov1963solution}, introduite dans les années 1960 et également connue sous le nom de régression de ridge. Cette méthode favorise des solutions lisses. La régularisation de Tikhonov peut également être interprétée comme un filtrage de Wiener (1949), utilisant les connaissances sur les densités spectrales du bruit et du signal. On peut également mentionner la pénalisation de Huber \cite{huber1992robust}, qui permet d'approcher la norme \(\ell_1\) et favorise des solutions parcimonieuses.

À partir des années 1990, la résolution des problèmes inverses a connu une révolution grâce aux pénalisations non lisses, parmi lesquelles la pénalisation par variation totale, proposée par Rudin, Osher et Fatemi (ROF) \cite{rudin1992nonlinear}, est sans aucun doute la plus connue. Sa définition originale a été formulée dans un contexte continu. En version discrétisée, plusieurs définitions de la variation totale existent, dépendant essentiellement du choix de l’opérateur de discrétisation. La formulation usuelle de la variation totale isotrope s'exprime comme suit :

\[
\phi(u) = \|Du\|_{2,1}  = \sum_{n=(n_1,n_2)} \sqrt{((D_1 u)_{n_1,n_2})^2 + ((D_2 u)_{n_1,n_2})^2},
\]

où \((D_1 u)_{n_1,n_2} = u_{n_1+1,n_2} - u_{n_1,n_2}\) et \((D_2 u)_{n_1,n_2} = u_{n_1,n_2+1} - u_{n_1,n_2}\).

La pénalisation par variation totale permet d'obtenir d'excellentes performances en débruitage, notamment lorsque l'image présente de vastes régions uniformes. Cependant, pour les images naturelles, cette méthode engendre un effet de staircasing (ou effet d'escalier)   que les utilisateurs préfèrent éviter. Par exemple, en astronomie, une version lissée de la variation totale est souvent utilisée : la pénalisation par variation totale hyperbolique \cite{charbonnier1997deterministic}, qui s'exprime comme suit :

\[
\phi(u) = \sum_{n} \sqrt{ \| (Du)_n \|_2^2 + \nu},
\]

introduisant un paramètre supplémentaire \(\nu > 0\) à ajuster. Cette approche présente l'avantage de lisser l'effet constant par morceaux et de fournir une transition plus fluide, ce qui peut sembler plus réaliste dans certaines modalités d'imagerie.



Il existe également des formes avancées de pénalisation par variation totale, telles que la variation totale généralisée (TGV) \cite{bredies2010total}, la variation totale non-locale, ou des pénalisations par tenseurs de structure \cite{chierchia2014nonlocal}.

Une troisième catégorie de pénalisation repose sur l’utilisation de pénalisations non convexes de type \(\ell_1\)-pondérée ou quadratique tronquée \cite{nikolova2005analysis}, qui introduisent cependant des difficultés algorithmiques associées à la minimisation.

Enfin, une dernière classe de pénalisation, basée sur l'apprentissage, est apparue récemment.


\subsection{Interprétation bayésienne}
Pour mieux comprendre la formulation générique (2), il peut être utile d’utiliser une approche bayésienne. Supposons que \( u \) et \( z \) soient des réalisations de vecteurs aléatoires \( U \) et \( Z \). L’estimation peut alors être effectuée à l’aide de la stratégie du Maximum A Posteriori (MAP). L’objectif est de trouver \( u \) qui maximise la distribution a posteriori \( \mu_{U|Z=z} \). Cette distribution peut être reformulée grâce au théorème de Bayes, puis simplifiée à l’aide du logarithme, comme suit :
\[
\hat{u} \in \operatorname{Argmin}_{u \in \mathbb{R}^N} \left( 
\underbrace{-\log \mu_{Z|U=u}(z)}_{\text{(vraisemblance)}} + 
\underbrace{-\log \mu_U(u)}_{\text{(a priori)}}
\right) \tag{3}
\]
Le premier terme de (3), qui mesure l’adéquation aux observations \( z \), dépend du modèle de formation des données (1). Par exemple, lorsque \( \epsilon \) représente un bruit blanc gaussien de variance \( \sigma^2 \) et \( A \in \mathbb{R}^{M \times N} \), la vraisemblance est donnée par :

\begin{equation}
\mu_{Z|U=u}(z) = (2\pi\sigma^2)^{-M/2} e^{-\frac{\|Au - z\|^2}{2\sigma^2}},
\end{equation}

ce qui conduit à l’expression suivante :

\begin{equation}
\psi(A\mathbf{u}, \mathbf{z}) = \frac{1}{2\sigma^2} \|Au - z\|^2 
\end{equation} 
Ce raisonnement peut également être utilisé pour justifier une attache aux données de type divergence de Kullback-Leibler dans le cas où le modèle d’acquisition suit un processus de Poisson \cite{pustelnik2016wavelet}.

Le second terme est lié aux informations a priori sur l’image originale et conduit à :
\begin{equation}
\phi(u) = -\log \mu_U(u).
\end{equation}
Dans le domaine de la restauration d’images, les modèles bayésiens sont souvent utilisés pour justifier le choix de l’attache aux données. En revanche, les modèles de pénalisation viennent plutôt de la littérature sur les ondelettes, la parcimonie ou les modèles variationnels continus.

\section{Opérateurs Proximaux}
Les avancées algorithmiques majeures pour la résolution de problèmes inverses proviennent de deux sources : l’adaptation des propriétés des fonctions \(\phi\) et \(\psi\), et les progrès en optimisation numérique.

Les travaux fondateurs sur les problèmes inverses sont liés à l’algorithme de gradient explicite et à ses versions accélérées (par exemple, Levenberg-Marquardt ou L-BFGS) \cite{nocedal1999numerical}. À partir des années 2000, l’apparition des méthodes proximales \cite{bauschke2017correction} (basées sur le sous-gradient implicite) a permis de traiter des volumes importants de données combinés à des pénalisations avancées (comme celles présentées dans la section précédente), offrant des gains significatifs en qualité de reconstruction.

Ces méthodes s’appuient sur la notion clé d’opérateur proximal \cite{moreau1965proximite}, défini pour une fonction \(\phi\) et tout \(\tau > 0\) comme :
\[
\forall z \in \mathbb{R}^N, \quad \text{prox}_{\tau}^{\phi}(z) = \arg \min_{ u\in \mathbb{R}^N} \left( \|u - z\|_2^2 + \tau \phi(u) \right) \tag{5}
\]
Cet opérateur généralise la projection sur un ensemble convexe \(C\), notée \(P_C\), en posant que \(\text{prox}_{\chi_C} = P_C\), où \(\chi_C(u) = 0\) si \(u \in C\), et \(+\infty\) sinon. Par exemple, l’opérateur proximal de la norme \(\ell_1\) correspond à une opération de seuillage doux de paramètre \(\tau\).

Les méthodes proximales unifient l’optimisation lisse sous contrainte et l’optimisation non lisse. Pour un problème de la forme $\min_{u \in \mathbb{R}^N} f(u)$, où \(f\) est convexe et non lisse, une itération de l’algorithme proximal (sous-gradient implicite) s’écrit :
\[
u^{[k+1]} = \text{prox}_{\tau_k}^{f}(u^{[k]}), \hspace{0.2cm} \text{où} \hspace{0.2cm} \tau_k > 0 \tag{6}
\]
Lorsque \(f\) est différentiable, le sous-gradient se réduit au gradient. La convergence de ces méthodes est plus flexible grâce à un choix de pas \(\tau_k\) moins contraignant.

Lorsqu’il s’agit de minimiser une somme de fonctions (par exemple \(f = \psi + \lambda \phi\)), il est nécessaire d’utiliser des algorithmes de type éclatement (splitting). L’algorithme explicite-implicite (forward-backward, FB) \cite{chaux2007variational} , est particulièrement adapté si \(\psi\) possède un gradient \(L\)-Lipschitz. Les itérations prennent la forme :

\[
u^{[k+1]} = \text{prox}_{\lambda}^{\phi} \Big(u^{[k]} - \tau_k \nabla \psi(u^{[k]})\Big), \tag{7}
\]

avec \(\tau_k < 2L^{-1}\). L’étape explicite gère l’inversion de \(A\), tandis que l’étape implicite applique les pénalisations. Toutefois, calculer l’opérateur proximal peut être coûteux, nécessitant parfois des sous-itérations. Dans ces cas, des algorithmes primaux-duaux \cite{chambolle2016introduction} sont plus efficaces.

Pour les fonctions non convexes, des résultats basés sur l’inégalité de Kurdyka-Łojasiewicz permettent de garantir la convergence vers un point critique. Ces méthodes sont particulièrement utiles pour des problèmes complexes, comme les pénalisations non convexes ou la déconvolution aveugle \cite{chouzenoux2014variable}.

\section{Introduction aux méthodes Plug and Play (PnP)}
Les méthodes Plug-and-Play (PnP) représentent une avancée significative dans le domaine de la restauration d'images, en intégrant les capacités des débruiteurs basés sur des réseaux de neurones profonds dans des algorithmes d'optimisation classiques. Ces méthodes exploitent la puissance de l'apprentissage profond pour améliorer la qualité des images tout en conservant une flexibilité qui permet d'adapter les techniques de régularisation à divers types de bruits et d'artéfacts.


Traditionnellement, la restauration d'images reposait sur des méthodes de régularisation classiques, telles que la méthode des moindres carrés ou des approches basées sur l'ADMM (Alternating Direction Method of Multipliers) et la méthode de gradient proximal (PGM). Ces techniques, bien que efficaces, présentent souvent des limitations en termes de flexibilité et de capacité à s'adapter à des scénarios variés de bruit. Avec l'émergence des réseaux de neurones convolutifs (CNN), il est devenu possible de concevoir des débruiteurs qui apprennent à partir de données réelles, offrant ainsi des performances supérieures par rapport aux méthodes classiques.

\subsection{Principes des Méthodes PnP}

L’originalité des méthodes Plug-and-Play (PnP) réside dans l’intégration d’un opérateur de débruitage au sein des algorithmes d’optimisation. Plutôt que de minimiser directement \( \phi(\mathbf{u}) \), ces méthodes remplacent l’opérateur proximal de \( \phi \) par un débruiteur \( R_\theta \), qui peut être un réseau neuronal pré-entraîné ou une méthode de débruitage classique.

Dans ce cadre, le terme \( \phi(\mathbf{u}) \) n'est pas explicitement défini. À la place, l'application d'un opérateur de débruitage \( R_\theta \) permet une approximation implicite. Ainsi, plutôt que de résoudre :
\[
\mathbf{u} \leftarrow \text{prox}_{\lambda}^{\phi}(\mathbf{v}),
\]
on effectue une mise à jour de la forme suivante :
\[
\mathbf{u} \leftarrow R_\theta(\mathbf{v}), 
\]
où \( \mathbf{v} \) représente une solution intermédiaire. L’opérateur \( R_\theta \) peut correspondre à un réseau neuronal convolutif (CNN) pré-entraîné ou à une méthode de débruitage traditionnelle, telle que le filtre NL-means.

Des algorithmes tels que le Deep Plug-and-Play Image Restoration (DPIR) exploitent cette approche pour résoudre efficacement les problèmes inverses. Par un processus itératif, ils réduisent progressivement le bruit ou les artéfacts présents dans l’image, améliorant ainsi la qualité de la reconstruction à chaque étape.

\subsection{Intégration des opérateurs PnP dans des méthodes d’optimisation}

Les méthodes Plug-and-Play (PnP) s’intègrent naturellement dans les algorithmes d’optimisation classiques, comme l’ADMM (Alternating Direction Method of Multipliers) et la méthode de gradient proximal (PGM). Elles remplacent l’étape classique de régularisation par un opérateur de débruitage \( R_\theta \), offrant ainsi une approche modulable et puissante pour résoudre des problèmes inverses.

\subsubsection{Méthode PnP-ADMM (Alternating Direction Method of Multipliers)}

L’ADMM reformule un problème d’optimisation en introduisant une variable auxiliaire afin de découpler les différents termes de la fonction objectif. Le problème s’écrit :
\[
\min_{\mathbf{u}, \mathbf{v}} \left( \psi(A\mathbf{u}, \mathbf{z}) + \lambda \phi(\mathbf{v}) \right) \quad \text{sous la contrainte } \mathbf{u} = \mathbf{v}.
\]
L’algorithme ADMM met à jour les variables de manière itérative selon trois étapes :
\begin{itemize}
    \item \textbf{Mise à jour de \( \mathbf{u} \)} :
    \[
    \mathbf{u}^{k+1} \leftarrow \arg\min_{\mathbf{u}} \left( \psi(A\mathbf{u}, \mathbf{z}) + \frac{\rho}{2} \| \mathbf{u} - \mathbf{v}^k + \mathbf{y}^k \|_2^2 \right), \hspace{0.2 cm} \text{où} \hspace{0.2 cm}  \rho \hspace{0.2 cm} \text{est un paramètre de pénalité}
    \]
    \item \textbf{Mise à jour de \( \mathbf{v} \)} :
     \begin{align*}
    \mathbf{v}^{k+1} &\leftarrow \arg\min_{\mathbf{v}} \left( \lambda \phi(\mathbf{v}) + \frac{\rho}{2} \| \mathbf{u}^{k+1} - \mathbf{v} + \mathbf{y}^k \|_2^2 \right) \\\\
    \mathbf{v}^{k+1} &\leftarrow  \text{prox}_{\frac{\lambda}{\rho}}^{\phi}( \mathbf{u}^{k+1} + \mathbf{y}^k). 
     \end{align*}
    \item \textbf{Mise à jour du multiplicateur de Lagrange \( \mathbf{y} \)} :
    \[
    \mathbf{y}^{k+1} \leftarrow \mathbf{y}^k + (\mathbf{u}^{k+1} - \mathbf{v}^{k+1})
    \]
\end{itemize}
Dans le cadre des méthodes PnP, l’étape de mise à jour de \( \mathbf{v} \) est remplacée par une application de l’opérateur de débruitage \( R_\theta \), ce qui donne :
\[
\mathbf{v}^{k+1} \leftarrow R_\theta(\mathbf{u}^{k+1} + \mathbf{y}^k).
\]
L’algorithme PnP-ADMM peut alors être résumé ainsi :
\begin{enumerate}
    \item Mettre à jour \( \mathbf{u} \) en minimisant \( \psi \),
    \item Appliquer le débruitage \( R_\theta \) pour mettre à jour \( \mathbf{v} \),
    \item Mettre à jour le multiplicateur \( \mathbf{y} \) pour imposer la contrainte \( \mathbf{u} = \mathbf{v} \).
\end{enumerate}

Cette approche assure une convergence rapide et stable, en particulier pour des problèmes mal posés.

\subsubsection{Méthode PnP-PGM (Proximal Gradient Method)}

La méthode de gradient proximal (PGM) est adaptée aux problèmes de la forme :

\[
\min_{\mathbf{u}} \left( \psi(A\mathbf{u}, \mathbf{z}) + \lambda \phi(\mathbf{u}) \right)
\]

Elle fonctionne par des mises à jour itératives comportant deux étapes principales :

\begin{itemize}
    \item \textbf{Descente de gradient sur le terme de fidélité \( \psi \)} :
    \[
    \mathbf{v} \leftarrow \mathbf{u}^k - \gamma \nabla \psi(A\mathbf{u}^k, \mathbf{z}),
    \hspace{0.2 cm} \text{où} \hspace{0.2 cm}  \gamma \hspace{0.2 cm} \text{est le pas de gradient}
    \]
    \item \textbf{Régularisation via l’opérateur proximal} :
    \[
    \mathbf{u}^{k+1} \leftarrow \text{prox}_{\lambda}^{\phi}(\mathbf{v})
    \]
\end{itemize}
En remplaçant ici l'opérateur proximal par un débruiteur \( R_\theta \). La mise à jour devient :
\[
\mathbf{u}^{k+1} \leftarrow R_\theta(\mathbf{v})
\]
L’algorithme PnP-PGM se résume alors à son tour comme suit :
\begin{enumerate}
    \item Effectuer une étape de descente de gradient sur \( \psi \),
    \item Appliquer le débruitage \( R_\theta \) pour obtenir la régularisation.
\end{enumerate}

Bien que plus simple à implémenter que PnP-ADMM, PnP-PGM peut se révéler moins robuste pour certains types de problèmes inverses complexes.

\subsection{Architecture du débruiteurs utilisé (DRUNet) :}

Le choix du débruiteur est crucial, car il détermine non seulement les performances de restauration, mais également le temps de calcul et la convergence de l'algorithme. Alors que les approches traditionnelles s’appuyaient principalement sur des débruiteurs classiques, les méthodes récentes privilégient désormais des modèles basés sur des réseaux de neurones convolutifs profonds (CNN). Cette transition, largement documentée dans la littérature, met en évidence les progrès significatifs réalisés grâce aux débruiteurs CNN dans les tâches de restauration d’images.

Cependant, les débruiteurs classiques les plus performants sont souvent gourmands en temps de calcul, ce qui limite leur utilisation dans des schémas itératifs plug-and-play nécessitant de nombreuses itérations. En revanche, l’intégration de débruiteurs basés sur des CNN permet de développer des algorithmes à la fois performants et plus rapides, optimisant ainsi le temps de calcul.

Un exemple emblématique dans la littérature PnP est l’architecture DRUNet \cite{zhang2021plug}, présentée dans la figure suivante. Ce modèle repose sur l’empilement de blocs ResNet \cite{he2016deep} intégrés dans une architecture de type UNet. Les débruiteurs basés sur UNet exploitent des informations apprises à l’avance sur les images, telles que leurs structures ou propriétés, pour améliorer les performances de restauration (\cite{ho2020denoising}, \cite{song2019generative}, \cite{song2021train}). À l’instar de DnCNN, ces modèles sont entraînés pour approximer le bruit ou une version redimensionnée de celui-ci, offrant ainsi des performances remarquables dans le cadre des schémas plug-and-play.

\begin{figure}[H]
\centering
\begin{adjustbox}{width=1.54 \linewidth, totalheight=0.3 \textheight, angle=0, scale= 0.65, minipage= 2\linewidth, margin= 0}
\includegraphics[width=1\textwidth]{denoiser_arch.png}
\end{adjustbox}
\caption{Architecture of the DRUNet denoiser (\cite{zhang2021plug})} 
    
    \label{fig:3}
\end{figure}   


\section{Comparaison TV vs DRUNet : Expérience Numérique} 

Dans cette section, nous analyserons les performances de l'algorithme FISTA combiné à la méthode de variation totale (TV) et au Plug-and-Play (PnP) utilisant le débruiteur DRUNet sur des images présentant différents niveaux de flou et de bruit, aussi bien faibles qu’élevés. Nous étudierons comment chaque méthode s’adapte à ces variations et comparerons leurs résultats en termes de qualité de reconstruction.

 Trois ensembles d’images distincts (Butterfly, Leaves et Starfish) sont utilisés pour évaluer les performances des deux approches en termes de PSNR (Peak Signal-to-Noise Ratio), une métrique quantitative où des valeurs plus élevées indiquent une meilleure qualité de reconstruction.
 
\subsection{Application TV vs DRUNet (Images faiblement bruitées)}
\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
\includegraphics[width=1\textwidth]{results/Imgs_denoised_sig15_comparison.png}
\end{adjustbox}
\caption{Débruitage d'images avec un niveau de bruit $\sigma = 0.06 \simeq \frac{15}{255}$} 
    
    \label{fig:4}
\end{figure}   

La \hyperref[fig:4]{Figure 1.4} montre la comparaison entre les méthodes TV (Variation Totale) et DRUNet (Deep Residual U-Net) pour le débruitage d’images présentant un faible niveau de bruit (\(\sigma=0.06\)).

Pour les trois exemples étudiés, le PSNR des images bruitées est d’environ 24.5 dB. Après débruitage, la méthode TV améliore le PSNR à environ 29 dB, tandis que DRUNet atteint des valeurs comprises entre 34 et 35 dB, soit un gain moyen de 5 à 6 dB en faveur de DRUNet.

En observant les résultats visuels, la méthode TV réduit efficacement le bruit mais adoucit légèrement les contours et atténue certains détails fins, particulièrement visibles sur les motifs des ailes du papillon ou les fines feuilles de la plante. En revanche, DRUNet conserve mieux les structures complexes et les textures, offrant une reconstruction à la fois plus réaliste et détaillée. 

Ces résultats confirment la supériorité de DRUNet, qui améliore à la fois le PSNR et la préservation des détails visuels.


\subsection{Application TV vs DRUNet (Images fortement bruitées)}
\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
\includegraphics[width=1\textwidth]{results/Imgs_denoised_sig50_comparison.png}
\end{adjustbox}
    \caption{Débruitage d'images avec un niveau de bruit
    $\sigma = 0.2 \simeq \frac{50}{255}$}
    \label{fig:5}
\end{figure}

La \hyperref[fig:5]{Figure 1.5} illustre l’efficacité des méthodes TV et DRUNet pour le débruitage d’images fortement bruitées (\(\sigma = 0.2\)). Les trois ensembles d’images permettent d’évaluer la capacité des deux approches à gérer ce niveau de bruit élevé.

Pour les images bruitées, le PSNR initial est d’environ 15 dB. Après application des algorithmes, la méthode TV parvient à améliorer le PSNR à des valeurs comprises entre 22 et 24 dB, tandis que DRUNet surpasse ces performances avec des valeurs atteignant 28 à 29 dB. Le gain de 6 à 7 dB en faveur de DRUNet est encore plus significatif dans ce scénario de bruit important, soulignant son efficacité accrue.

En termes de qualité visuelle, la méthode TV, bien qu'efficace pour réduire l'intensité du bruit, présente des limites en termes de préservation des détails. Les contours deviennent flous, et les textures complexes, comme les motifs des ailes du papillon ou les surfaces de l’étoile de mer, perdent en clarté. DRUNet, en revanche, conserve une meilleure fidélité aux structures fines et aux textures complexes. Les détails visuels, notamment sur les motifs de l'image des feuilles, sont significativement mieux préservés.

Ces résultats confirment que DRUNet est particulièrement performant pour traiter des niveaux de bruit élevés, combinant une amélioration significative du PSNR avec une meilleure qualité visuelle des images restaurées.

\subsection{Application TV vs DRUNet (Images faiblement floutées)}

\subsubsection{Défloutages d'images}

\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
    \includegraphics[width=1\textwidth]{results/Imgs_deblurred_sig_1_comparison.png}
\end{adjustbox}
    \caption{ Défloutage d'une image avec un niveau de flou $\sigma = 1$}
    \label{fig:6}
\end{figure} 

La \hyperref[fig:6]{Figure 1.6} illustre les performances des méthodes TV et DRUNet pour la restauration d’images présentant un faible niveau de flou (\(\sigma = 1\)). 

Pour les images floues, le PSNR initial varie entre 23.87 et 27.80 dB, selon les exemples. Après application des algorithmes, la méthode TV atteint des valeurs comprises entre 35 et 37 dB, tandis que DRUNet présente des performances légèrement inférieures, avec des valeurs allant de 32 à 35 dB. Ces résultats montrent que TV est plus efficace pour améliorer le PSNR dans le cas d’un faible flou.

De même, en termes de qualité visuelle, la méthode TV semble mieux préserver les motifs complexes par rapport à DRUNet, comme en témoignent les détails des ailes du papillon et l’arrière-plan de l’étoile de mer.

En conclusion, pour un faible niveau de flou, la méthode TV se distingue par une qualité visuelle supérieure et un meilleur gain en PSNR comparé à DRUNet. Cette différence peut s'expliquer par la capacité de DRUNet à s’appuyer sur des données apprises, tandis que TV utilise une régularisation ciblée spécifiquement adaptée à ce type de dégradation.


\subsubsection{Évolution comparative du PSNR}

\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
    \includegraphics[width=1\textwidth]{results/Imgs_deblurred_sig_1_psnr_plot.png}
\end{adjustbox}
    \caption{Évolution comparative du PSNR pour différentes méthodes de débruitage (\(\sigma = 1\))}
    \label{fig:7}
\end{figure} 

La \hyperref[fig:7]{Figure 1.7} montre l’évolution du PSNR en fonction des itérations pour les méthodes TV et DRUNet appliquées à notre ensembles d’images avec un niveau de flou fixé à \(\sigma = 1\).

Les courbes des méthodes TV (bleu, vert, violet) progressent rapidement dans les premières itérations, atteignant un plateau élevé autour de 35-37 dB. Cette évolution met en évidence l’efficacité de la méthode TV pour corriger un faible niveau de flou, grâce à sa régularisation ciblée qui favorise la préservation des contours et des zones uniformes.

En comparaison, les courbes des méthodes DRUNet (orange, rouge, marron) affichent une convergence plus lente, atteignant des valeurs stabilisées entre 32 et 35 dB. Bien que DRUNet ne parvienne pas à surpasser TV en termes de PSNR, son comportement plus régulier traduit une capacité à produire des résultats visuellement cohérents et naturels.

Ces résultats soulignent que, pour un faible niveau de flou, la méthode TV offre une meilleure performance quantitative (PSNR), mais DRUNet reste néanmoins une alternative compétitive.


\subsection{Application TV vs DRUNet (Images fortement floutées)}

\subsubsection{Défloutages d'images}

\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
    \includegraphics[width=1\textwidth]{results/Imgs_deblurred_sig_3_comparison.png}
\end{adjustbox}
    \caption{Défloutage d'une image avec un niveau de flou $\sigma = 3$}
    \label{fig:8}
\end{figure} 

La \hyperref[fig:8]{Figure 1.8} compare les performances des méthodes TV et DRUNet pour la restauration d’images fortement floutées (\(\sigma = 3\)). Les performances des deux approches sont évaluées en termes de PSNR et de qualité visuelle.

Pour les images floutées, les PSNR initiaux varient entre 16.14 et 21.43 dB, selon les images. Après restauration, la méthode TV atteint des valeurs comprises entre 22 et 25 dB, tandis que DRUNet reste légèrement en retrait avec des scores allant de 19.8 à 23.9 dB. Ces résultats montrent que, dans le cas d’un flou important, TV offre un avantage en termes de PSNR, bien qu’il ne soit pas aussi marqué qu’avec un flou faible.

En termes de qualité visuelle, des différences notables apparaissent. La méthode TV parvient à mieux restituer les contours principaux et les motifs complexes, notamment sur les détails de l’étoile de mer et des ailes du papillon. DRUNet, en revanche, peine à restituer ces détails complexes avec la même précision.

En conclusion, pour un niveau élevé de flou, la méthode TV se distingue par une performance quantitative et une qualité visuelle légèrement supérieures à celles de DRUNet. Cette différence pourrait refléter une limite de DRUNet, notamment dans la gestion de certaines incertitudes ou du flou, qu’il ne prend pas explicitement en compte.

\subsubsection{Évolution comparative du PSNR}
\begin{figure}[H]
\centering
\begin{adjustbox}{width=0.985\linewidth, totalheight=0.47 \textheight, angle=0, scale= 0.9, minipage= 4.2\linewidth, margin= 0}
    \includegraphics[width=1\textwidth]{results/Imgs_deblurred_sig_3_psnr_plot.png}
\end{adjustbox}
    \caption{Évolution comparative du PSNR pour différentes méthodes de défloutage (\(\sigma = 3\))}
    \label{fig:9}
\end{figure} 

La \hyperref[fig:9]{Figure 1.9} illustre l'évolution du PSNR en fonction des itérations pour les méthodes TV et DRUNet appliquées à des images fortement floutées (\(\sigma = 3\)).

Les courbes des méthodes TV (bleu, vert, violet) montrent une progression constante avec un plateau atteint après environ 150 itérations. Les valeurs finales de PSNR se situent entre 22 et 25 dB, ce qui reflète la capacité de TV à corriger partiellement les effets d’un flou important tout en préservant les contours principaux. La progression lente mais régulière indique une optimisation continue au fil des itérations.

En revanche, les courbes des méthodes DRUNet (orange, rouge, marron) atteignent un plateau plus rapidement, dès les 50 premières itérations, avec des PSNR finaux légèrement inférieurs, entre 19.8 et 23.9 dB. Bien que DRUNet converge plus rapidement, il montre des performances limitées dans la gestion d’un flou important, probablement en raison de sa dépendance à des données d’apprentissage spécifiques et à une généralisation imparfaite dans ce contexte.

Ces résultats mettent en évidence une différence clé entre les deux approches : TV excelle dans le traitement de flous sévères grâce à sa régularisation ciblée et continue à s’améliorer avec davantage d’itérations, tandis que DRUNet, bien qu’efficace dans les premières étapes, est limité par son architecture prédéfinie, particulièrement pour des dégradations non courantes.


\newpage

\chapter{Apprentissage de fonction de régularisation convexe pour la résolution de problèmes inverses}
Le texte de ce chapitre est adapté de la thèse de Alexis Marie Frederic GOUJON \cite{goujon2024towards}.

\section*{Introduction}

L'émergence de techniques classiques et d'approches basées sur l'apprentissage profond pour la reconstruction d'images a conduit à des améliorations significatives en termes de qualité. Cependant, ces nouvelles méthodes présentent souvent des limitations en matière de fiabilité  et d'explicabilité. Cela a suscité un intérêt croissant pour développer des solutions qui maintiennent ces gains de performance tout en remédiant à ces faiblesses.

Dans ce chapitre, nous abordons cette problématique en revisitant des régularisateurs formulés comme la somme de fonctions convexes en crête. Le gradient de ces régularisateurs est paramétré à l’aide d’un réseau de neurones simple, constitué d’une seule couche cachée avec des fonctions d’activation croissantes et apprenables. Ce réseau est entraîné en quelques minutes, pour agir comme un débruiteur gaussien multi-étapes.

Les expériences numériques réalisées sur des tâches de débruitage, ainsi que sur des problèmes de reconstruction en tomographie computérisée (CT) et en imagerie par résonance magnétique (IRM), montrent des résultats prometteurs. En effet, les méthodes proposées permettent d’atteindre des améliorations non seulement en termes de qualité de reconstruction, mais aussi en termes de robustesse et de fiabilité. Ces résultats surpassent ceux des approches traditionnelles offrant des garanties similaires, ouvrant ainsi de nouvelles perspectives pour une reconstruction d'images à la fois performante et explicable.

\section{Architecture du Régularisateur}
\subsection{Paramètres Généraux}

Notre objectif est d'apprendre un régularisateur \( R \) pour résoudre le problème variationnel suivant :  
\[
x^* \in \arg \min_{x \in \mathbb{R}^d} \left( \| Hx - y \|_2^2 + R(x) \right),
\]
qui doit être efficace pour une large variété de problèmes mal posés. À l'instar du cadre Plug-and-Play (PnP), nous considérons le débruitage :  
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R(x) \right),
\]
comme problème de base pour l'entraînement, où \( y \) représente l'image bruitée. Pour privilégier l'interprétabilité et la fiabilité, nous utilisons un régularisateur simple sous la forme d’une somme de fonctions convexes en crête :  
\[
R(x) = \sum_{i} \psi_i(w_i^T x),
\]
et adoptons sa version convolutionnelle. Plus précisément, la régularité d'une image \( x \) est mesurée par :  
\[
R: x \mapsto \sum_{i=1}^{N_C} \sum_{k \in \mathbb{Z}^2} \psi_i \left( (h_i * x)[k] \right),
\]
où \( h_i \) est la réponse impulsionnelle d'un filtre convolutionnel 2D, \( (h_i * x)[k] \) est la valeur du \( k \)-ème pixel de l'image filtrée \( h_i * x \), et \( N_C \) est le nombre de canaux. Considérant que \( R(x) \) est un cas particulier de \( R(x) = \sum_{i} \psi_i(w_i^T x) \), nous adopterons cette dernière notation générique pour simplifier les équations.

Nous exprimons \( R \) en fonction d’un ensemble de paramètres apprenables \( \theta \) et notons \( R_\theta \) pour souligner cette dépendance. Par ailleurs, nous supposons que les profils convexes \( \psi_i \) possèdent des dérivées continues et Lipschitz-continues, soit \( \psi_i \in C^{1,1}(\mathbb{R}) \).

\subsection{Réseau de neurones à pas de gradient}

Sous ces hypothèses, l’image débruitée obtenue via :  
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R_\theta(x) \right),
\]
peut être interprétée comme le point fixe unique de l’opérateur \( T_{R_\theta,\lambda,\alpha} : \mathbb{R}^d \to \mathbb{R}^d \) défini par :  
\[
T_{R_\theta,\lambda,\alpha}(x) = x - \alpha \left( (x - y) + \lambda \nabla R_\theta(x) \right).
\]
Les itérations de cet opérateur mettent en œuvre une descente de gradient avec un pas \( \alpha \), qui converge si :  
\[
\alpha \in \left(0, \frac{2}{1 + \lambda L_\theta}\right),
\]
où \( L_\theta = \text{Lip}(\nabla R_\theta) \) est la constante de Lipschitz du gradient \( \nabla R_\theta \). Nous imposons cette contrainte sur \( \alpha \) pour garantir la convergence.

Le gradient du régularisateur générique \( R(x) = \sum_{i} \psi_i(w_i^T x) \) est donné par :  
\[
\nabla R_\theta(x) = W^T \sigma(Wx),
\]
où \( W = [w_1 \cdots w_p]^T \in \mathbb{R}^{p \times d} \) et \( \sigma \) est une fonction d’activation point par point dont les composants \( (\sigma_i = \psi'_i)_{i=1}^p \) sont Lipschitz-continus et croissants. Dans notre implémentation, les fonctions \( \sigma_i \) sont partagées entre chaque canal de \( W \).

Ainsi, l’opérateur de pas de gradient devient :  
\[
T_{R_\theta,\lambda,\alpha}(x) = (1 - \alpha)x + \alpha \left( y - \lambda W^T \sigma(Wx) \right).
\]
Cet opérateur correspond à un réseau de neurones convolutionnel à une couche cachée, incluant un biais et une connexion de contournement. Nous appelons ce modèle un réseau de neurones à pas de gradient. L’entraînement d’un tel réseau donne naissance à un CRR-NN (Convex Ridge Regularization Neural Network).

\section{Caractérisation des bonnes fonctions de profil}

Dans cette section, nous présentons des résultats théoriques qui justifient notre choix des profils \( \psi_i \) ou, de manière équivalente, de leurs dérivées \( \sigma_i = \psi'_i \).

\subsection{Existence des minimisateurs et stabilité de la reconstruction}

La convexité de \( R_\theta \) seule ne suffit pas à garantir que l'ensemble des solutions :  
\[
x^* \in \arg \min_{x \in \mathbb{R}^d} \left( \| Hx - y \|_2^2 + R(x) \right)
\]  
est non vide, surtout lorsque \( H \) est une matrice avancée et non inversible. Cependant, avec des régularisateurs en crête convexe, cette limitation peut être surmontée sous une condition légère imposée aux fonctions \( \psi_i \), comme démontré dans la proposition ci-dessous.

\subsection*{Proposition 1}

Soit \( H \in \mathbb{R}^{m \times d} \) et \( \psi_i : \mathbb{R} \to \mathbb{R} \), pour \( i = 1, \ldots, p \), des fonctions convexes. Si, pour tout \( i = 1, \ldots, p \), nous avons \( \arg \min_{t \in \mathbb{R}} \psi_i(t) \neq \emptyset \), alors :  
\[
\emptyset \neq \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| Hx - y \|_2^2 + \sum_{i=1}^p \psi_i(w_i^T x) \right).
\]

\subsection*{Proposition 2}

Soit \( H \in \mathbb{R}^{m \times d} \) et \( \psi_i : \mathbb{R} \to \mathbb{R} \), pour \( i = 1, \ldots, p \), des fonctions convexes, continuellement différentiables, avec \( \arg \min_{t \in \mathbb{R}} \psi_i(t) \neq \emptyset \). Pour tout \( y_1, y_2 \in \mathbb{R}^m \), soit :  
\[
x_q \in \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| Hx - y_q \|_2^2 + \sum_{i=1}^p \psi_i(w_i^T x) \right),
\]
où \( q = 1, 2 \) sont les reconstructions correspondantes. Alors, la relation suivante est satisfaite :  
\[
\| Hx_1 - Hx_2 \|_2 \leq \| y_1 - y_2 \|_2.
\]

\subsection{Expressivité des Fonctions de Profil}
Le réseau de neurones à pas de gradient \( T_{R_\theta,\lambda,\alpha} \) est le composant clé de notre procédure d'entraînement. Ici, nous examinons son expressivité en fonction du choix des fonctions d'activation \( \sigma_i \) utilisées pour paramétrer \( \nabla R_\theta \).

Soit \( C_{0,1}^+(\mathbb{R}) \), l'ensemble des fonctions scalaires Lipschitz-continues et croissantes sur \( \mathbb{R} \), et \( LS_m^+(\mathbb{R}) \), le sous-ensemble des splines linéaires croissantes avec au plus \( m \) nœuds. Nous définissons également :  
\[
E(\mathbb{R}^d) = \left\{ W^T \sigma(W \cdot) : W \in \mathbb{R}^{p \times d}, \sigma_i \in C_{0,1}^+(\mathbb{R}) \right\},
\]
et, pour tout \( \Omega \subset \mathbb{R}^d \),
\[
E(\Omega) = \left\{ f|_{\Omega} : f \in E(\mathbb{R}^d) \right\}.
\]

Pour mesurer les propriétés des fonctions sur un domaine \( \Omega \), nous utilisons les normes suivantes :
\[
\|f\|_{C(\Omega)} := \sup_{x \in \Omega} \|f(x)\| \quad \text{et} \quad \|f\|_{{C^1}(\Omega)} := \sup_{x \in \Omega} \|f(x)\| + \sup_{x \in \Omega} \|J_f(x)\|,
\]
où \( J_f(x) \) représente le jacobien de \( f \) en \( x \).

Parmi les fonctions d'activation populaires, la ReLU (Rectified Linear Unit) est Lipschitz-continue et croissante. Cependant, son expressivité reste limitée, comme le démontre la Proposition suivante.

\subsection*{Proposition 3}
Soit \( \Omega \subset \mathbb{R}^d \) compact avec un intérieur non vide. Alors, l'ensemble :
\[
\left\{ W^T \text{ReLU}(W \cdot - b) : W \in \mathbb{R}^{p \times d}, b \in \mathbb{R}^p \right\}
\text{ n'est pas dense par rapport à } \| \cdot \|_{C(\Omega)} \text{ dans } E(\Omega).\]

\subsection*{Proposition 4}
Soit \( \Omega \subset \mathbb{R}^d \) compact et \( m \geq 2 \). Alors, l'ensemble :
\[
\left\{ W^T \sigma(W \cdot) : W \in \mathbb{R}^{p \times d}, \sigma_i \in LS_m^+(\mathbb{R}) \right\} 
\text{ est dense par rapport à } \| \cdot \|_{C(\Omega)} \text{ dans }  E(\Omega).\]

\subsection*{Corollaire}

Soit \( \Omega \subset \mathbb{R}^d \) convexe et compact avec un intérieur non vide. Les régularisateurs de la forme :
\[ R: x \mapsto \sum_{i} \psi_i(w_i^T x),\]
avec des jacobiennes appartenant à l'ensemble :
\[
\left\{ W^T \sigma(W \cdot) : W \in \mathbb{R}^{p \times d}, \sigma_i \in LS_m^+(\mathbb{R}) \right\},
\]
sont denses dans :
\[
\left\{ \sum_{i=1}^p \psi_i(w_i^T x) : \psi_i \in C^{1,1}(\mathbb{R}) \text{ convexe}, w_i \in \mathbb{R}^d \right\}
\text{par rapport à la norme}  \|\cdot\|_{{C^1}(\Omega)}.\]

En revanche, cette densité ne tient pas si les jacobiennes sont limitées à l'ensemble :
\[
\left\{ W^T \text{ReLU}(W \cdot - b) : W \in \mathbb{R}^{p \times d}, b \in \mathbb{R}^p \right\}.
\]

\section{Implémentation}

\subsection{Entraînement d'un débruiteur à pas de gradient multiple}

Soit \( \{x_m\}_{m=1}^M \) un ensemble d’images propres, et \( \{y_m\}_{m=1}^M = \{x_m + n_m\}_{m=1}^M \) leurs versions bruitées, où \( n_m \) représente le bruit ajouté. Pour apprendre les paramètres de \( R_\theta \), basés sur le problème :  
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R(x) \right),
\]
nous minimisons la perte suivante :  
\[
(\theta^*_t, \lambda^*_t) \in \arg \min_{\theta, \lambda} \sum_{m=1}^M L \left( T_t R_{\theta, \lambda, \alpha}(y^m), x^m \right),
\]
où \( T_t R_{\theta, \lambda, \alpha} \) désigne la composition \( t \)-fois du réseau de neurones à pas de gradient :  
\[
T_{R_{\theta, \lambda, \alpha}}(x) = (1 - \alpha)x + \alpha \left( y - \lambda W^T \sigma(Wx) \right).
\]

En théorie, pour \( t = \infty \), nous obtenons le point fixe \( T^\infty R_{\theta, \lambda, \alpha}(y^m) \). Cependant, résoudre ce problème d’optimisation bilatéral complet à l’aide de techniques comme la différentiation implicite \cite{pramanik2023memory,chen2014insights} est coûteux. Dans notre cadre contraint, il est suffisant d’approximer ce point fixe à l’aide d’un nombre fini \( t \) d’itérations. Cela définit un réseau de neurones débruitant en \( t \) étapes, \( T^t R_{\theta, \lambda, \alpha} \), entraîné pour approximer \( x^m \) à partir de \( y^m \). En pratique :  
\[
T^t R_{\theta, \lambda, \alpha}(y^m) \approx x^m, \quad \forall m = 1, \ldots, M.
\]

Cette approche peut être vue comme une minimisation partielle de :  
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R(x) \right),
\]
avec une estimation initiale \( y_m \), ou, de manière équivalente, comme un \textcolor{red}{unfolding} de l’algorithme de descente de gradient sur \( t \) itérations, avec des paramètres partagés entre les itérations \cite{aggarwal2018modl,pramanik2020deep}. Pour de faibles valeurs de \( t \), cela permet d’obtenir un débruiteur rapide à évaluer, bien que son interprétabilité soit limitée puisqu’il n’est pas nécessairement un opérateur proximal.

Une fois le réseau de neurones à pas de gradient entraîné, le \( R_\theta \) correspondant peut être intégré dans :  
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R(x) \right),
\]
et utilisé pour résoudre complètement le problème d’optimisation, donnant lieu à un débruiteur proximal interprétable. En pratique, transformer un débruiteur en \( t \) étapes en un débruiteur proximal nécessite un ajustement de \( \lambda \) et l’ajout d’un paramètre d’échelle, comme décrit au chapitre 1.

Notre méthode présente des similarités avec les réseaux variationnels (VN) proposés dans \cite{kobler2017variational}, mais aussi des différences fondamentales. Dans \cite{kobler2017variational}, les profils convexes apprenables sont paramétrés par des fonctions de base radiales, et seule la dernière étape de la descente de gradient est incluse dans le passage avant. Les auteurs y ont observé qu’une augmentation de \( t \) dégradait les performances de débruitage, ce qui n’est pas le cas dans notre architecture, où une augmentation de \( t \) améliore au contraire la qualité de reconstruction.

\subsection{Implémentation des contraintes}

L'apprentissage du débruiteur en \( t \) étapes est soumis aux contraintes suivantes :

\begin{enumerate}
    \item Les fonctions d'activation \( \sigma_i \) doivent être croissantes, ce qui impose une contrainte de convexité sur \( \psi_i \).
    \item Les fonctions d'activation \( \sigma_i \) doivent s'annuler à une certaine valeur (contrainte d'existence).
    \item Le pas de gradient dans :
    \[
    T_{R_{\theta, \lambda, \alpha}}(x) = (1 - \alpha)x + \alpha \left( y - \lambda W^T \sigma(Wx) \right),
    \]
    doit satisfaire \( \alpha \in \left(0, \frac{2}{1 + \lambda L_\theta}\right) \) afin d’assurer la convergence de la descente de gradient.
\end{enumerate}

Les méthodes utilisées pour imposer ces contraintes ont un impact significatif sur la performance du modèle final et doivent donc être soigneusement conçues.

\subsubsection{Splines Monotones}

Pour répondre simultanément aux contraintes (1) et (2), nous utilisons des splines linéaires apprenables \( \sigma_{c_i} : \mathbb{R} \to \mathbb{R} \), comme proposé dans \cite{bohra2021learning,bohra2020learning}. Ces splines sont définies sur \( (M + 1) \) nœuds uniformément espacés \( \nu_m = (m - M/2) \Delta \) pour \( m = 0, \ldots, M \), où \( \Delta \) est l’espacement des nœuds. Pour simplifier, nous supposons que \( M \) est pair. Les paramètres apprenables \( c_i = (c_{i m})_{m=0}^M \in \mathbb{R}^{M+1} \) définissent les valeurs de \( \sigma_{c_i} \) aux nœuds : \( \sigma_{c_i}(\nu_m) = c_{i m} \). Ces splines sont étendues par des valeurs constantes \( c_{i 0} \) pour \( (-\infty, \nu_0] \) et \( c_{i M} \) pour \( [\nu_M, +\infty) \).

La régularité d’une image \( x \) est mesurée par :
\[
R_\theta(x) = \sum_{i} \psi_i(w_i^T x),
\]
\text{ où }  \(\psi_i\)= sont des fonctions convexes associées aux splines \(\sigma_{c_i}\).

Soit \( D \in \mathbb{R}^{M \times (M+1)} \) la matrice des différences finies unidimensionnelles définie par \( (D c_i)_m = c_{i m+1} - c_{i m} \) pour \( m = 0, \ldots, M-1 \). Les splines sont croissantes si et seulement si :
\[
D c_i \geq 0.
\]
Pour garantir cette propriété, nous reparamétrons les splines linéaires en \( \sigma_{P^{\uparrow}}(c_i) \), où :
\[
P^{\uparrow}(c_i) = C D^{\dagger} \text{ReLU}(D c_i),
\]
avec \( D^{\dagger} \) l’inverse de Moore-Penrose de \( D \), et \( C \) une matrice centrant la sortie pour que \( c_{i M/2+1} = 0 \). Cette projection maintient les différences finies non négatives et met à zéro celles qui sont négatives.

\subsubsection{Avantages et Implémentation}

La reparamétrisation \( \sigma_{P^{\uparrow}}(c_i) \) permet d’utiliser des paramètres apprenables non contraints \( c_i \). Contrairement à une descente de gradient projetée traditionnelle \cite{kobler2017variational}, cette méthode intègre directement les contraintes via \( P^{\uparrow} \) dans le calcul des gradients :
\[
\begin{aligned}
(\theta^*_t, \lambda^*_t) \in \arg \min_{\theta, \lambda} \sum_{m=1}^M L \left( T_t R_{\theta, \lambda, \alpha}(y^m), x^m \right).
\end{aligned}
\]

Pour une efficacité accrue, \( P^{\uparrow} \) est implémenté avec la fonction \texttt{cumsum}, ce qui évite la construction explicite de \( D^{\dagger} \) et réduit considérablement le coût computationnel. Cette approche offre une alternative robuste aux méthodes traditionnelles, où une descente de gradient projetée peut entraîner des performances sous-optimales dans les problèmes non convexes.

Les profils \( \psi_i \) associés satisfont à la convexité et à la condition \( \psi'_i(0) = \sigma_i(0) = 0 \), ce qui garantit l’existence de solutions au problème :
\[
x^* \in \arg \min_{x \in \mathbb{R}^d} \left( \| Hx - y \|_2^2 + R(x) \right).
\]

\subsubsection{Régularisation favorisant la parcimonie}

L'utilisation de fonctions d'activation apprenables peut entraîner un surapprentissage, réduisant la capacité de généralisation à des opérateurs \( H \) arbitraires. Pour pallier cela, il est essentiel de favoriser des splines linéaires simples offrant de bonnes performances tout en utilisant un nombre minimal de nœuds. Cela est réalisé en pénalisant la variation totale d'ordre supérieur \( \| L P^{\uparrow}(c_i) \|_1 \) de chaque spline \( \sigma_{P^{\uparrow}}(c_i) \), où \( L \in \mathbb{R}^{(M-1) \times (M+1)} \) est la matrice des différences finies d'ordre secondaire.

La perte d'entraînement finale s'exprime alors comme:
\[
\sum_{m=1}^{M} L \left( T_{R_{\theta, \lambda, \alpha}}(y^m), x^m \right) + \eta \sum_{i=1}^{p} \| L P^{\uparrow}(c_i) \|_1,
\]
où \( \eta > 0 \) ajuste la régularisation. Pour une perspective théorique approfondie sur la variation totale d'ordre supérieur, voir \cite{unser2019representer}, et pour des validations expérimentales, \cite{bohra2020learning}.

\subsubsection{Étapes de gradient convergentes}

La contrainte sur le pas \( \alpha \) garantit la convergence des itérations du réseau de neurones \( T_{R_{\theta, \lambda, \alpha}}^t \) vers le véritable minimiseur:
\[
x^* \in \arg \min_{x \in \mathbb{R}^d} \left( \| Hx - y \|_2^2 + R(x) \right),
\]
lorsque \( t \to \infty \). Elle apporte également de la stabilité à l'entraînement, même pour de petites valeurs de \( t \). Une estimation précise de la constante de Lipschitz \( \text{Lip}(\nabla R_\theta) \) est cruciale pour exploiter pleinement le modèle. La Proposition ci-dessous fournit une borne améliorée:

\subsubsection*{Proposition 5}
Soit \( L_\theta \) la constante de Lipschitz de \( \nabla R_\theta(x) = W^T \sigma(Wx) \), avec \( W \in \mathbb{R}^{p \times d} \) et \( \sigma_i \in C^{0,1}_{\uparrow}(\mathbb{R}) \). En posant \( \Sigma_\infty = \text{diag}(\|\sigma'_1\|_\infty, \ldots, \|\sigma'_p\|_\infty) \), on obtient:
\[
L_\theta \leq \|W^T \Sigma_\infty W\|,
\]
ce qui est plus serré que la borne naïve:
\[
L_\theta \leq L_\sigma \|W\|^2.
\]

\subsubsection{Des gradients aux potentiels}

Pour récupérer le régularisateur \( R \) à partir de son gradient \( \nabla R \), on détermine les profils \( \psi_i \), tels que \( \psi'_i = \sigma_i P_{\uparrow}(c_i) \). Chaque \( \psi_i \) est un spline quadratique par morceaux exprimé comme:
\[
\psi_i(x) = \sum_{k \in \mathbb{Z}} d_{i,k} \beta_2^+ \left( x - k \Delta \right),
\]
où \( \beta_2^+ \) est le B-spline causale de degré 2. Les coefficients \( (d_{i,k})_{k \in \mathbb{Z}} \) sont définis par:
\[
d_{i,k} - d_{i,k-1} = (P_{\uparrow}(c_i))_k,
\]
avec une constante additive arbitraire. Cette constante n’affecte pas \( \nabla R \). Grâce au support fini de \( \beta_2^+ \), \( \psi_i \) et \( R \) peuvent être évalués efficacement; voir \cite{unser1999splines} pour plus de détails.

\subsection{Renforcement de l'universalité du régularisateur}

Le régularisateur \( R_\theta \) appris dépend de la tâche d'entraînement (débruitage) et du niveau de bruit. Pour résoudre un problème inverse générique, nous proposons d'incorporer un paramètre d'échelle ajustable \( \mu \in \mathbb{R}^+ \), en plus de la force de régularisation \( \lambda \). Le problème à résoudre devient:
\[
\arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \|Hx - y\|_2^2 + \frac{\lambda}{\mu} R_\theta(\mu x) \right).
\]

Bien que le paramètre d'échelle soit sans effet pour les régularisateurs homogènes tels que Tikhonov et TV, il est connu pour améliorer les performances dans le cadre PnP lorsqu'il est appliqué à l'entrée du débruiteur \cite{xu2020boosting}. 

Lors de l'entraînement des débruiteurs en \( t \) étapes, nous apprenons également le paramètre d'échelle \( \mu \). Ainsi, le pas de gradient \( T_{R_{\theta, \lambda, \alpha}}(x) \), défini comme:
\[
T_{R_{\theta, \lambda, \alpha}}(x) = x - \alpha \left( (x - y) + \lambda \nabla R_\theta(x) \right),
\]
devient:
\[
T_{R_{\theta, \lambda, \mu, \alpha}}(x) = x - \alpha \left( (x - y) + \lambda \nabla R_\theta(\mu x) \right),
\]
avec la contrainte \( \alpha < \frac{2}{1 + \lambda \mu \text{Lip}(\nabla R_\theta)} \). Cette adaptation permet de mieux exploiter le régularisateur dans des scénarios variés, améliorant ainsi l'universalité et la robustesse du modèle.


\section{Connexions aux approches d'apprentissage profond}
Nos CRR-NNs proposés possèdent une seule couche non linéaire, ce qui est plutôt inhabituel à l'ère de l'apprentissage profond. Pour explorer davantage leurs propriétés théoriques, nous discutons brièvement de deux méthodes d'apprentissage profond réussies, à savoir le PnP et la conception explicite de régularisateurs convexes, et nous énonçons leurs versions les plus stables et interprétables

\subsection{Dénosieurs Plug-and-Play et Dénosieurs Moyennés}
\subsubsection{Dénosieurs Plug-and-Play Convergents}

La procédure d'entraînement proposée pour les CRR-NNs aboutit à un régularisateur convexe \( R_\theta \), dont l'opérateur proximal 
\[
x^* = \arg \min_{x \in \mathbb{R}^d} \left( \frac{1}{2} \| x - y \|_2^2 + \lambda R(x) \right)
\]
agit comme un dénoiseur performant. Inversement, l'opérateur proximal peut être remplacé par un dénoiseur générique \( D \) dans les algorithmes proxy, ce qui constitue le cadre Plug-and-Play (PnP). Dans l'algorithme PnP-FBS, dérivé du problème 
\[
x^* \in \arg \min_{x \in \mathbb{R}^d} \left( \| Hx - y \|_2^2 + R(x) \right)
\]
\cite{beck2009fast}, la reconstruction est réalisée itérativement via 
\[
x_{k+1} = D \left( x_k - \alpha H^T (H x_k - y) \right),
\]
où \( \alpha \) est le pas d'apprentissage, et \( D : \mathbb{R}^d \to \mathbb{R}^d \) est un dénoiseur générique.

Pour garantir la convergence des itérations 
\[
x_{k+1} = D \left( x_k - \alpha H^T (H x_k - y) \right),
\]
les conditions suffisantes suivantes doivent être remplies :
\begin{enumerate}
    \item \( D \) est moyenné, c'est-à-dire \( D = \beta N + (1 - \beta) \text{Id} \), où \( \beta \in (0, 1) \) et \( N : \mathbb{R}^d \to \mathbb{R}^d \) est une application non expansive ;
    \item \( \alpha \in \left[ 0, \frac{2}{\|H\|_2^2} \right) \) ;
    \item l'opérateur de mise à jour \( x_{k+1} = D \left( x_k - \alpha H^T (H x_k - y) \right) \) possède un point fixe.
\end{enumerate}

Cependant, la condition (i) ne garantit pas que \( D \) est l'opérateur proximal d'un régularisateur convexe \( R \). Par conséquent, son interprétation comme opérateur proxi reste limitée. En revanche, la condition (ii) implique que l'application \( x \mapsto \left( x - \alpha H^T (Hx - y) \right) \) est moyennée. Comme la moyenneté est préservée par composition, l'ensemble des itérations reste moyenné (voir \cite{lecun1989backpropagation} pour des détails supplémentaires). 

Avec la condition (iii), la convergence des itérations découle directement du théorème de convergence d'Opial. En outre, il est démontré que les dénoiseurs moyennés avec \( \beta \leq \frac{1}{2} \) produisent une carte de reconstruction stable dans le domaine des mesures \cite{beck2009fast}, dans un sens analogue à celui présenté dans la Proposition 2 pour les CRR-NNs.

La non-expansivité de \( D \) est également une hypothèse courante pour prouver la convergence d'autres schémas PnP, tels que les algorithmes basés sur le gradient \cite{pramanik2023memory}. Dans ce cadre, le gradient \( \nabla R \) du régularisateur utilisé dans les algorithmes de reconstruction est remplacé par un opérateur monotone appris \( F = \text{Id} - D \). L'opérateur \( D \), interprété comme un dénoiseur, est supposé non expansif afin de garantir la convergence.

\bibliographystyle{plain}
\bibliography{ref.bib}

\end{document}